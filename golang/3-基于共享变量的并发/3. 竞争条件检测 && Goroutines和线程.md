```toc

```


## 竞争条件检测

只要在 `go build，go run` 或者 `go test` 命令后面加上 `-race` 的 `flag`，就会使编译器创建一个你的应用的“修改”版或者一个附带了能够记录所有运行期对共享变量访问工具的 `test`，并且会记录下每一个读或者写共享变量的 `goroutine` 的身份信息。另外，修改版的程序会记录下所有的同步事件，比如 `go` 语句，`channel` 操作，以及对 ` (*sync. Mutex). Lock `，` (*sync. WaitGroup). Wait ` 等等的调用。（完整的同步事件集合是在 `The Go Memory Model` 文档中有说明，该文档是和语言文档放在一起的。译注：[https://golang.org/ref/mem](https://golang.org/ref/mem) ）

竞争检查器会检查这些事件，会寻找在哪一个 ` goroutine` 中出现了这样的 `case`，例如其读或者写了一个共享变量，这个共享变量是被另一个 `goroutine` 在没有进行干预同步操作便直接写入的。这种情况也就表明了是对一个共享变量的并发访问，即数据竞争。这个工具会打印一份报告，内容包含变量身份，读取和写入的 `goroutine` 中活跃的函数的调用栈。这些信息在定位问题时通常很有用。

竞争检查器会报告所有的已经发生的数据竞争。然而，它只能检测到运行时的竞争条件；并不能证明之后不会发生数据竞争。所以为了使结果尽量正确，请保证你的测试并发地覆盖到了你的包。

## Goroutines 和线程

### 动态栈

每一个 `OS` 线程都有一个固定大小的内存块（一般会是 `2MB`）来做栈，这个栈会用来存储当前正在被调用或挂起（指在调用其它函数时）的函数的内部变量。这个固定大小的栈同时很大又很小。因为 `2MB` 的栈对于一个小小的 `goroutine` 来说是很大的内存浪费，比如对于我们用到的，一个只是用来 `WaitGroup` 之后关闭 `channel` 的 `goroutine` 来说。而对于 `go` 程序来说，同时创建成百上千个 `goroutine` 是非常普遍的，如果每一个 `goroutine` 都需要这么大的栈的话，那这么多的 `goroutine` 就不太可能了。除去大小的问题之外，固定大小的栈对于更复杂或者更深层次的递归函数调用来说显然是不够的。修改固定的大小可以提升空间的利用率，允许创建更多的线程，并且可以允许更深的递归调用，不过这两者是没法同时兼备的。

相反，一个 `goroutine` 会以一个很小的栈开始其生命周期，一般只需要 `2KB`。一个 `goroutine` 的栈，和操作系统线程一样，会保存其活跃或挂起的函数调用的本地变量，但是和 `OS` 线程不太一样的是，一个 `goroutine` 的栈大小并不是固定的；栈的大小会根据需要动态地伸缩。而 `goroutine` 的栈的最大值有 `1GB`，比传统的固定大小的线程栈要大得多，尽管一般情况下，大多 `goroutine` 都不需要这么大的栈。


### Goroutines 调度

`OS` 线程会被操作系统内核调度。每几毫秒，一个硬件计时器会中断处理器，这会调用一个叫作 `scheduler` 的内核函数。这个函数会挂起当前执行的线程并将它的寄存器内容保存到内存中，检查线程列表并决定下一次哪个线程可以被运行，并从内存中恢复该线程的寄存器信息，然后恢复执行该线程的现场并开始执行线程。因为操作系统线程是被内核所调度，所以从一个线程向另一个“移动”需要完整的上下文切换，也就是说，保存一个用户线程的状态到内存，恢复另一个线程的到寄存器，然后更新调度器的数据结构。这几步操作很慢，因为其局部性很差需要几次内存访问，并且会增加运行的 `cpu` 周期。

`Go` 的运行时包含了其自己的调度器，这个调度器使用了一些技术手段，比如 `m: n` 调度，因为其会在 `n` 个操作系统线程上多工（调度）`m` 个 `goroutine`。`Go` 调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的 `Go` 程序中的 `goroutine`（译注：按程序独立）。

和操作系统的线程调度不同的是，`Go` 调度器并不是用一个硬件定时器，而是被 `Go` 语言“建筑”本身进行调度的。例如当一个 `goroutine` 调用了 `time.Sleep`，或者被 `channel` 调用或者 `mutex` 操作阻塞时，调度器会使其进入休眠并开始执行另一个 `goroutine`，直到时机到了再去唤醒第一个 `goroutine`。因为这种调度方式不需要进入内核的上下文，所以重新调度一个 `goroutine` 比调度一个线程代价要低得多。


### GoMaxProcs

`Go` 的调度器使用了一个叫做 `GOMAXPROCS` 的变量来决定会有多少个操作系统的线程同时执行 `Go` 的代码。其默认的值是运行机器上的 `CPU` 的核心数，所以在一个有 8 个核心的机器上时，调度器一次会在 8 个 `OS` 线程上去调度 `GO` 代码。（`GOMAXPROCS` 是前面说的 `m: n` 调度中的 `n`）。在休眠中的或者在通信中被阻塞的 `goroutine` 是不需要一个对应的线程来做调度的。在 `I/O` 中或系统调用中或调用非 `Go` 语言函数时，是需要一个对应的操作系统线程的，但是 `GOMAXPROCS` 并不需要将这几种情况计算在内。

你可以用 `GOMAXPROCS` 的环境变量来显式地控制这个参数，或者也可以在运行时用 `runtime. GOMAXPROCS` 函数来修改它。我们在下面的小程序中会看到 `GOMAXPROCS` 的效果，这个程序会无限打印 0 和 1。

```go
for {
    go fmt.Print(0)
    fmt.Print(1)
}

$ GOMAXPROCS=1 go run hacker-cliché.go
111111111111111111110000000000000000000011111...

$ GOMAXPROCS=2 go run hacker-cliché.go
010101010101010101011001100101011010010100110...
```

在第一次执行时，最多同时只能有一个 `goroutine` 被执行。初始情况下只有 `main goroutine` 被执行，所以会打印很多 1。过了一段时间后，`GO` 调度器会将其置为休眠，并唤醒另一个 `goroutine`，这时候就开始打印很多 0 了，在打印的时候，`goroutine` 是被调度到操作系统线程上的。在第二次执行时，我们使用了两个操作系统线程，所以两个 `goroutine` 可以一起被执行，以同样的频率交替打印 0 和 1。我们必须强调的是 `goroutine` 的调度是受很多因子影响的，而 `runtime` 也是在不断地发展演进的，所以这里的你实际得到的结果可能会因为版本的不同而与我们运行的结果有所不同。


### Goroutines 没有 ID 号

在大多数支持多线程的操作系统和程序语言中，当前的线程都有一个独特的身份（`id`），并且这个身份信息可以以一个普通值的形式被很容易地获取到，典型的可以是一个 `integer` 或者指针值。这种情况下我们做一个抽象化的 ` thread-local storage `（线程本地存储，多线程编程中不希望其它线程访问的内容）就很容易，只需要以线程的 ` id ` 作为 ` key ` 的一个 ` map ` 就可以解决问题，每一个线程以其 ` id ` 就能从中获取到值，且和其它线程互不冲突。

`goroutine` 没有可以被程序员获取到的身份（`id`）的概念。这一点是设计上故意而为之，由于 `thread-local storage` 总是会被滥用。比如说，一个 `web server` 是用一种支持 `tls` 的语言实现的，而非常普遍的是很多函数会去寻找 `HTTP` 请求的信息，这代表它们就是去其存储层（这个存储层有可能是 `tls`）查找的。这就像是那些过分依赖全局变量的程序一样，会导致一种非健康的“距离外行为”，在这种行为下，一个函数的行为可能并不仅由自己的参数所决定，而是由其所运行在的线程所决定。因此，如果线程本身的身份会改变——比如一些 `worker` 线程之类的——那么函数的行为就会变得神秘莫测。

`Go` 鼓励更为简单的模式，这种模式下参数（译注：外部显式参数和内部显式参数。` tls ` 中的内容算是"外部"隐式参数）对函数的影响都是显式的。这样不仅使程序变得更易读，而且会让我们自由地向一些给定的函数分配子任务时不用担心其身份信息影响行为。


## 示例：并发的非阻塞缓存


我们将使用下面的 `httpGetBody` 函数作为我们需要缓存的函数的一个样例。这个函数会去进行 `HTTP GET` 请求并且获取 `http` 响应 `body`。对这个函数的调用本身开销是比较大的，所以我们尽量避免在不必要的时候反复调用。

```go
func httpGetBody(url string) (interface{}, error) {
    resp, err := http.Get(url)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    return ioutil.ReadAll(resp.Body)
}
```

最后一行稍微隐藏了一些细节。`ReadAll` 会返回两个结果，一个 `[]byte` 数组和一个错误，不过这两个对象可以被赋值给 `httpGetBody` 的返回声明里的 `interface{}` 和 `error` 类型，所以我们也就可以这样返回结果并且不需要额外的工作了。我们在 `httpGetBody` 中选用这种返回类型是为了使其可以与缓存匹配。

下面是我们要设计的cache的第一个“草稿”：

```go
// Package memo provides a concurrency-unsafe
// memoization of a function of type Func.
package memo

// A Memo caches the results of calling a Func.
type Memo struct {
    f     Func
    cache map[string]result
}

// Func is the type of the function to memoize.
type Func func(key string) (interface{}, error)

type result struct {
    value interface{}
    err   error
}

func New(f Func) *Memo {
    return &Memo{f: f, cache: make(map[string]result)}
}

// NOTE: not concurrency-safe!
func (memo *Memo) Get(key string) (interface{}, error) {
    res, ok := memo.cache[key]
    if !ok {
        res.value, res.err = memo.f(key)
        memo.cache[key] = res
    }
    return res.value, res.err
}
```

`Memo` 实例会记录需要缓存的函数 `f`（类型为 `Func`），以及缓存内容（里面是一个 `string` 到 `result` 映射的 `map`）。每一个 `result` 都是简单的函数返回的值对儿——一个值和一个错误值。继续下去我们会展示一些 `Memo` 的变种，不过所有的例子都会遵循上面的这些方面。

下面是一个使用 `Memo` 的例子。对于流入的 `URL` 的每一个元素我们都会调用 `Get`，并打印调用延时以及其返回的数据大小的 `log`：

```go
m := memo.New(httpGetBody)
for url := range incomingURLs() {
    start := time.Now()
    value, err := m.Get(url)
    if err != nil {
        log.Print(err)
    }
    fmt.Printf("%s, %s, %d bytes\n",
    url, time.Since(start), len(value.([]byte)))
}
```

我们可以使用测试包（后面内容）来系统地鉴定缓存的效果。从下面的测试输出，我们可以看到 `URL` 流包含了一些重复的情况，尽管我们第一次对每一个 URL 的 ` (*Memo).Get ` 的调用都会花上几百毫秒，但第二次就只需要花 1 毫秒就可以返回完整的数据了。

```sh
$ go test -v gopl.io/ch9/memo1
=== RUN   Test
https://golang.org, 175.026418ms, 7537 bytes
https://godoc.org, 172.686825ms, 6878 bytes
https://play.golang.org, 115.762377ms, 5767 bytes
http://gopl.io, 749.887242ms, 2856 bytes
https://golang.org, 721ns, 7537 bytes
https://godoc.org, 152ns, 6878 bytes
https://play.golang.org, 205ns, 5767 bytes
http://gopl.io, 326ns, 2856 bytes
--- PASS: Test (1.21s)
PASS
ok  gopl.io/ch9/memo1   1.257s
```

这个测试是顺序地去做所有的调用的。

由于这种彼此独立的 `HTTP` 请求可以很好地并发，我们可以把这个测试改成并发形式。可以使用 `sync.WaitGroup` 来等待所有的请求都完成之后再返回。

```go
m := memo.New(httpGetBody)
var n sync.WaitGroup
for url := range incomingURLs() {
    n.Add(1)
    go func(url string) {
        start := time.Now()
        value, err := m.Get(url)
        if err != nil {
            log.Print(err)
        }
        fmt.Printf("%s, %s, %d bytes\n",
        url, time.Since(start), len(value.([]byte)))
        n.Done()
    }(url)
}
n.Wait()
```

这次测试跑起来更快了，然而不幸的是貌似这个测试不是每次都能够正常工作。我们注意到有一些意料之外的 `cache miss`（缓存未命中），或者命中了缓存但却返回了错误的值，或者甚至会直接崩溃。

但更糟糕的是，有时候这个程序还是能正确的运行（译：也就是最让人崩溃的偶发 `bug`），所以我们甚至可能都不会意识到这个程序有 ` bug `。但是我们可以使用-race 这个 flag 来运行程序，竞争检测器会打印像下面这样的报告：

```sh
$ go test -run=TestConcurrent -race -v gopl.io/ch9/memo1
=== RUN   TestConcurrent
...
WARNING: DATA RACE
Write by goroutine 36:
  runtime.mapassign1()
      ~/go/src/runtime/hashmap.go:411 +0x0
  gopl.io/ch9/memo1.(*Memo).Get()
      ~/gobook2/src/gopl.io/ch9/memo1/memo.go:32 +0x205
  ...
Previous write by goroutine 35:
  runtime.mapassign1()
      ~/go/src/runtime/hashmap.go:411 +0x0
  gopl.io/ch9/memo1.(*Memo).Get()
      ~/gobook2/src/gopl.io/ch9/memo1/memo.go:32 +0x205
...
Found 1 data race(s)
FAIL    gopl.io/ch9/memo1   2.393s
```

`memo.go` 的 `32` 行出现了两次，说明有两个 `goroutine` 在没有同步干预的情况下更新了 `cache map`。这表明 `Get` 不是并发安全的，存在数据竞争。

```
28  func (memo *Memo) Get(key string) (interface{}, error) {
29      res, ok := memo.cache(key)
30      if !ok {
31          res.value, res.err = memo.f(key)
32          memo.cache[key] = res
33      }
34      return res.value, res.err
35  }
```

最简单的使 `cache` 并发安全的方式是使用基于监控的同步。只要给 `Memo` 加上一个 `mutex`，在 `Get` 的一开始获取互斥锁，`return` 的时候释放锁，就可以让 `cache ` 的操作发生在临界区内了：

```go
type Memo struct {
    f     Func
    mu    sync.Mutex // guards cache
    cache map[string]result
}

// Get is concurrency-safe.
func (memo *Memo) Get(key string) (value interface{}, err error) {
    memo.mu.Lock()
    res, ok := memo.cache[key]
    if !ok {
        res.value, res.err = memo.f(key)
        memo.cache[key] = res
    }
    memo.mu.Unlock()
    return res.value, res.err
}
```

测试依然并发进行，但这回竞争检查器“沉默”了。不幸的是对于 `Memo` 的这一点改变使我们完全丧失了并发的性能优点。每次对 `f` 的调用期间都会持有锁，`Get` 将本来可以并行运行的 `I/O` 操作串行化了。我们本章的目的是完成一个无锁缓存，而不是现在这样的将所有请求串行化的函数的缓存。

下一个 `Get` 的实现，调用 `Get` 的 `goroutine` 会两次获取锁：查找阶段获取一次，如果查找没有返回任何内容，那么进入更新阶段会再次获取。在这两次获取锁的中间阶段，其它 `goroutine` 可以随意使用 `cache`。

```go
func (memo *Memo) Get(key string) (value interface{}, err error) {
    memo.mu.Lock()
    res, ok := memo.cache[key]
    memo.mu.Unlock()
    if !ok {
        res.value, res.err = memo.f(key)

        // Between the two critical sections, several goroutines
        // may race to compute f(key) and update the map.
        memo.mu.Lock()
        memo.cache[key] = res
        memo.mu.Unlock()
    }
    return res.value, res.err
}
```

这些修改使性能再次得到了提升，但有一些 `URL` 被获取了两次。这种情况在两个以上的 `goroutine` 同一时刻调用 `Get` 来请求同样的 `URL` 时会发生。多个 `goroutine` 一起查询 `cache`，发现没有值，然后一起调用 `f` 这个慢不拉叽的函数。在得到结果后，也都会去更新 `map`。其中一个获得的结果会覆盖掉另一个的结果。

理想情况下是应该避免掉多余的工作的。而这种“避免”工作一般被称为 `duplicate suppression`（重复抑制/避免）。下面版本的 `Memo` 每一个 `map` 元素都是指向一个条目的指针。每一个条目包含对函数 `f` 调用结果的内容缓存。与之前不同的是这次 `entry` 还包含了一个叫 `ready` 的 `channel`。在条目的结果被设置之后，这个 `channel` 就会被关闭，以向其它 `goroutine` 广播去读取该条目内的结果是安全的了。

```go
type entry struct {
    res   result
    ready chan struct{} // closed when res is ready
}

func New(f Func) *Memo {
    return &Memo{f: f, cache: make(map[string]*entry)}
}

type Memo struct {
    f     Func
    mu    sync.Mutex // guards cache
    cache map[string]*entry
}

func (memo *Memo) Get(key string) (value interface{}, err error) {
    memo.mu.Lock()
    e := memo.cache[key]
    if e == nil {
        // This is the first request for this key.
        // This goroutine becomes responsible for computing
        // the value and broadcasting the ready condition.
        e = &entry{ready: make(chan struct{})}
        memo.cache[key] = e
        memo.mu.Unlock()

        e.res.value, e.res.err = memo.f(key)

        close(e.ready) // broadcast ready condition
    } else {
        // This is a repeat request for this key.
        memo.mu.Unlock()

        <-e.ready // wait for ready condition
    }
    return e.res.value, e.res.err
}
```

现在 `Get` 函数包括下面这些步骤了：获取互斥锁来保护共享变量 `cache map`，查询 `map` 中是否存在指定条目，如果没有找到那么分配空间插入一个新条目，释放互斥锁。如果存在条目的话且其值没有写入完成（也就是有其它的 `goroutine` 在调用 `f` 这个慢函数）时，`goroutine` 必须等待值 `ready` 之后才能读到条目的结果。而想知道是否 `ready` 的话，可以直接从 `ready channel` 中读取，由于这个读取操作在 `channel` 关闭之前一直是阻塞。

如果没有条目的话，需要向 `map` 中插入一个没有准备好的条目，当前正在调用的 `goroutine` 就需要负责调用慢函数、更新条目以及向其它所有 `goroutine` 广播条目已经 `ready` 可读的消息了。

条目中的 `e.res.value` 和 `e.res.err` 变量是在多个 `goroutine` 之间共享的。创建条目的 `goroutine` 同时也会设置条目的值，其它 `goroutine` 在收到"`ready`"的广播消息之后立刻会去读取条目的值。尽管会被多个 `goroutine` 同时访问，但却并不需要互斥锁。`ready channel` 的关闭一定会发生在其它 `goroutine` 接收到广播事件之前，因此第一个 `goroutine` 对这些变量的写操作是一定发生在这些读操作之前的。不会发生数据竞争。

这样并发、不重复、无阻塞的 `cache` 就完成了。

上面这样 `Memo` 的实现使用了一个互斥量来保护多个 `goroutine` 调用 `Get` 时的共享 `map` 变量。不妨把这种设计和前面提到的把 `map` 变量限制在一个单独的 `monitor goroutine ` 的方案做一些对比，后者在调用 `Get` 时需要发消息。


```go
package ch9  
  
// A result is the result of calling a Func.  
type result struct {  
   value interface{}  
   err   error  
}  
  
type entry struct {  
   res   result  
   ready chan struct{} // closed when res is ready  
}  
  
// A request is a message requesting that the Func be applied to key.  
type request struct {  
   key      string  
   response chan<- result // the client wants a single result  
}  
  
type Memo struct{ requests chan request }  
  
// New returns a memoization of f.  Clients must subsequently call Close.
func New(f Func) *Memo {  
   memo := &Memo{requests: make(chan request)}  
   go memo.server(f)  
   return memo  
}  
  
func (memo *Memo) Get(key string) (interface{}, error) {  
   response := make(chan result)  
   memo.requests <- request{key, response}  
   res := <-response  
   return res.value, res.err  
}  
  
func (memo *Memo) Close() { close(memo.requests) }  
  
func (memo *Memo) server(f Func) {  
   cache := make(map[string]*entry)  
   for req := range memo.requests {  
      e := cache[req.key]  
      if e == nil {  
         // This is the first request for this key.  
         e = &entry{ready: make(chan struct{})}  
         cache[req.key] = e  
         go e.call(f, req.key) // call f(key)  
      }  
      go e.deliver(req.response)  
   }}  
  
func (e *entry) call(f Func, key string) {  
   // Evaluate the function.  
   e.res.value, e.res.err = f(key)  
   // Broadcast the ready condition.  
   close(e.ready)  
}  
  
func (e *entry) deliver(response chan<- result) {  
   // Wait for the ready condition.  
   <-e.ready  
   // Send the result to the client.  
   response <- e.res  
}
```

这里首先注意，`server` 就是一个监听器，我们可以看到当调用 `Get` 方法时，往 `memo.requests` 中写入了内容，然后 `server` 方法就可以读取出来，在 `memo.requests` 未关闭时，`server` 一直可以持续监听读取（这也告诉我们，在 `memo` 不使用后需要调用 `Close` 方法关闭）。通过读取到的内容来判断是需要调用网络请求，还是可以直接返回。如果是第一次调用，那么在关闭 `ready` 之前，其他后面调用会一直因为 `ready` 未关闭而阻塞，达到并发安全目的。

最后就是调用 `New` 方法时初始化来 `requests` 这个 `channel`。
