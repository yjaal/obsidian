
```toc

```

## 说明

账号：我的谷歌邮箱

chatGPT 地址： https://chat.openai.com/

vpn 代理需要切换到非中国，包括香港


## API 使用

### 基本调用

**curl**

```sh
curl https://api.openai.com/v1/chat/completions \
-H "Authorization: Bearer API_KEY" \
-H "Content-Type: application/json" \
-d '{"model": "gpt-3.5-turbo","messages": [{"role": "user", "content": "What is the OpenAI mission?"}]}'
```

这里的 `API_KEY` 需要从 `openai` 官网获取（` Personal->View API keys `）

响应

```json
{
    "id": "chatcmpl-6txyfTkK3A2sbJZROnVfY05HXY2xf",
    "object": "chat.completion",
    "created": 1678796613,
    "model": "gpt-3.5-turbo-0301",
    "usage": {
        "prompt_tokens": 14,
        "completion_tokens": 92,
        "total_tokens": 106
    },
    "choices": [
        {
            "message": {
                "role": "assistant",
                "content": "\n\nThe OpenAI mission is to ensure that artificial intelligence (AI) benefits humanity by developing and promoting friendly AI for the betterment of society. The organization aims to create safe and beneficial AI by conducting research, advocating for policies, and setting ethical standards to guide the development and deployment of AI. OpenAI’s ultimate goal is to build advanced AI that can advance human knowledge, provide new solutions to societal problems, and help create a better future for all."
            },
            "finish_reason": "stop",
            "index": 0
        }
    ]
}
```

**python**

```python
import openai  
  
  
def main():  
    openai.proxy = f'http://127.0.0.1:1087'  
    openai.api_key = 'API_LKEY'  
    # 发送请求  
    response = openai.Completion.create(  
        engine="curie",  
        prompt="Hello, I'm ChatGPT! What can I help you with today?",  
        max_tokens=50,  
        timeout=60  # 设置超时时间为60秒  
    )  
  
    # 输出响应  
    print(response.choices[0].text)  
  
  
if __name__ == '__main__':  
    main()
```

这里有两点需要注意：
- 不同的场景 ，创建请求的方式是不同的，请求响应结构也不同
- `openai` 包需要实现下载
- 需要设置代理，同时不同版本的 `openai` 使用方式也不同，这里的版本是 `0.27.2`

同时注意：
这里的 `response` 是

```json
{
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "\uff0c\u4f46\u5728\u6700\u8fd1\u597d\u4e45\u4e0d\u89c1\u7684\u7eaf\u7cb9\u9690\u5f62King \u6e38\u73a9\u8f66\u4e00\u4e9b\uff01\uff01\n"
    }
  ],
  "created": 1678848343,
  "id": "cmpl-6uBR1dJXxdfcISyQgV1IyALitnEN9",
  "model": "curie",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 50,
    "prompt_tokens": 17,
    "total_tokens": 67
  }
}
```

### Models

查询所有模型

```sh
curl https://api.openai.com/v1/models -H 'Authorization: Bearer YOUR_API_KEY'
```

```json
{
  "object": "list",
  "data": [
    {
      "id": "babbage",
      "object": "model",
      "created": 1649358449,
      "owned_by": "openai",
      "permission": [
        {
          "id": "modelperm-49FUp5v084tBB49tC4z8LPH5",
          "object": "model_permission",
          "created": 1669085501,
          "allow_create_engine": false,
          "allow_sampling": true,
          "allow_logprobs": true,
          "allow_search_indices": false,
          "allow_view": true,
          "allow_fine_tuning": false,
          "organization": "*",
          "group": null,
          "is_blocking": false
        }
      ],
      "root": "babbage",
      "parent": null
    },
    {
      "id": "davinci",
      "object": "model",
      "created": 1649359874,
      "owned_by": "openai",
      "permission": [
        {
          "id": "modelperm-U6ZwlyAd0LyMk4rcMdz33Yc3",
          "object": "model_permission",
          "created": 1669066355,
          "allow_create_engine": false,
          "allow_sampling": true,
          "allow_logprobs": true,
          "allow_search_indices": false,
          "allow_view": true,
          "allow_fine_tuning": false,
          "organization": "*",
          "group": null,
          "is_blocking": false
        }
      ],
      "root": "davinci",
      "parent": null
    },{...}]
}    
```


可以单独查询某一个模型信息

```sh
curl https://api.openai.com/v1/models/text-davinci-003 \
  -H 'Authorization: Bearer YOUR_API_KEY'
```


### Competion

这个词的含义我们可以这样理解

> "`Completion`"指的是使用 `OpenAI API` 的 `GPT` 模型生成文本的过程，它是一种无监督的生成模式，其中输入是一些文本或片段，而模型生成的输出是完整的文本段落或文章，这种方式通常被用于生成新的文章、故事、自动摘要或翻译等任务。
> 
>相比之下，聊天是一种交互式的对话方式，它涉及到两个或多个人之间的实时对话，其中一个人提出问题或者发表观点，另一个人则给出回应。在这种情况下，人们通常期望回应是具有上下文、相关性、适当的情感和语气的，这需要聊天机器人具有很高的智能水平。

一般这种请求的发送链接是

```sh
POST https://api.openai.com/v1/completions
```

#### Request body

**model**    `string, Required`

>指定模型

**prompt**  `string or array, Optional  Defaults to <|endoftext|>`
  
> 字符串和字符串数组很好理解，这个 `token` 数组其实可以理解为一个字典数组，比如
> `"tokens": [ {"text": "The", "id": 0}, {"text": "quick", "id": 1} ]` 但是里面字段名字好像并没有具体规定

**suffix**   `string Optional Defaults to null`

> 这个就是用于我们在响应末尾加上一段自定义的话，比如 "您还有什么别的需要吗？"


**max_tokens** `integer Optional Defaults to 16`

> 指定结果生成的最大 `token` 数，用于控制生成文本的最大长度，以 `token` 为单位。
> 
> 在 `NLP` 领域中，`token` 是一个文本序列中的基本单位，通常是一个单词或一个标点符号。因此，` max_tokens ` 参数实际上是指定生成的文本结果中包含的 `token` 的最大数量。
> 例如，如果将 `max_tokens` 设置为 `50`，而模型生成的文本结果包含了 `50` 个 `token`，那么这个文本结果将会是最终的输出。如果生成的文本结果包含的 `token` 数量超过了 ` max_tokens ` 指定的值，那么模型将会截断超出的部分，并返回长度为 ` max_tokens ` 的文本结果。
> 
> 需要注意的是，`max_tokens` 并不是一个硬性限制，而是一个指导性的参数，模型生成的文本结果可能略微超过指定的值。此外，`max_tokens` 的最大值取决于所使用的模型和 `API` 版本，不同的模型和 `API` 版本可能会支持不同的 ` max_tokens ` 取值范围。

> The token count of your prompt plus `max_tokens` cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096).


**temperature** `number Optional Defaults to 1`

> 取值在 `0～2` 之间，值越大得到的结果越随机。比如 `0.2` 就比 `0.8` 得到的结果更为确定，相似度更高。建议不要和 `top_p` 一起使用。

**top_p** `number Optional Defaults to 1`

> 这个作用和 `temperature` 的作用类似，称为核采样。比如设置为 5，那么模型会生成 5 个可能的文本结果，并从中选择最有可能的一个作为最终的结果。取值范围取决于使用的模型和 API 版本。一般来说值越大，生成的文本多样性越高

**n** `integer Optional Defaults to 1`

> 上面的参数 `top_p` 是从多个结果中选出多少个，那么这个参数就是直接指定模型生成多少个结果，并且全部返回。要注意的是，值如果太大，可能会影响响应速度。同时注意参数 `max_tokens` 和 `stop` 的影响。

**stream**  `boolean Optional Defaults to false`

> 指定结果是流式返回还是一次性返回。如果为 `true`，表示流式返回，否则表示一次性返回。两种方式返回的数据结构不一样。流式返回可能生成多个文本，多个文本结果都将以单独的 `json` 对象形式返回，而不是作为数组中的一个元素返回。

**logprobs**  `integer Optional Defaults to null`

> 用于控制 `API` 是否返回每个生成文本结果的 `token log probabilities`。如果设置为 ` 0 `，则不返回 `log probabilities`；如果设置为一个正整数 `n`，则返回生成文本结果中前 `n` 个 `token` 的 `log probabilities`。这个参数主要用于调试和分析模型生成的文本结果。
> 
> 最大值为 5，如果需要更大的，需要联系官方。


**echo**  `boolean Optional Defaults to false`

> 用于控制 `API` 是否在生成每个文本结果时将 `prompt` 文本一起返回。如果设置为 ` True `，则返回每个文本结果生成时的完整 `prompt`，包括之前生成的所有文本结果。这个参数主要用于调试和分析模型的生成方式。

**stop** `string or array Optional Defaults to null`

> 是一个字符串或字符串列表，用于指定生成文本时的停止条件。当生成文本中包含任何一个指定的字符串时，API会停止继续生成并返回结果。这个参数可以用于控制生成文本的长度、语法和意义等方面。

**presence_penalty** `number Optional Defaults to 0`

> 这个参数是一个实数，用于控制生成文本时是否避免使用已经出现过的 ` token`。如果设置为一个正实数，则生成的文本结果中会尽可能避免使用之前出现过的 ` token `，从而增加文本的多样性和新颖性。这个参数的取值范围通常在 `-2.0` 到 `2.0` 之间。

**frequency_penalty**  `number Optional Defaults to 0`

> 用于控制生成文本时是否避免使用出现频率较高的 `token`。如果设置为一个正实数，则生成的文本结果中会尽可能避免使用出现频率较高的 `token`，从而增加文本的多样性和新颖性。这个参数的取值范围通常在 `-2.0` 到 `2.0` 之间

**best_of** `integer Optional Defaults to 1`

> 用于指定 API 在多次生成文本后返回最佳的文本结果。具体来说，`API` 会生成 ` n ` 个文本结果，然后从中选择得分最高的一个返回。这个参数主要用于控制 `API` 的输出质量和稳定性。

**logit_bias**  `map Optional Defaults to null`

> 这个参数是一个字典，用于指定生成文本时使用的 `logit` 偏置。具体来说，`logit` 偏置是一组用于调整模型生成概率的参数，可以用于指定生成文本的情感、语气、风格等方面。这个参数的具体格式和用法可以参考 `OpenAI API` 文档中的说明。

**user**  `string Optional`

> 用于指定生成文本时的用户 `ID`。具体来说，用户 `ID` 是一个可以用于标识不同用户或应用程序的唯一标识符，可以用于记录和分析 `API` 使用情况。这个参数可以用于多用户或多应用程序的情况下，对 `API` 使用情况进行分析


```sh
curl https://api.openai.com/v1/completions \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY' \
  -d '{
  "model": "text-davinci-003",
  "prompt": "Say this is a test",
  "max_tokens": 7,
  "temperature": 0
}'
```

